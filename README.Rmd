---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# RfEmpImp <a href='https://github.com/shangzhi-hong/RfEmpImp'><img src='man/figures/logo.png' align="right" height="160"/></a>

[![Lifecycle: maturing](https://img.shields.io/badge/lifecycle-maturing-blue.svg)](https://www.tidyverse.org/lifecycle/#maturing)  
An R package for random-forest-empowered imputation of missing Data

## Random-forest-based multiple imputation evolved
This is the repository for R package `RfEmpImp`, an R package for multiple
imputation using chained random forests (RF).  
This R package is an implementation for the prediction-based and node-based 
imputation algorithms and currently operates under the multiple imputation
computation framework [`mice`](https://CRAN.R-project.org/package=mice).  
This R package contains both newly proposed and improved algorithms for
random-forest-based multiple imputation of missing data.  
For more details of the implemented imputation algorithms, please refer to:
[arXiv:2004.14823](https://arxiv.org/abs/2004.14823) (further updates pending).


## Installation
This R package is already submitted to CRAN, but it may take a while before 
being published.  
Currently, interested users can install this package from GitHub:  
```r
# Install from CRAN (Pending)
# install.packages("RfEmpImp")
# Install from GitHub online
if(!"remotes" %in% installed.packages()) install.packages("remotes")
remotes::install_github("shangzhi-hong/RfEmpImp")
# Install from released source package
install.packages(path_to_source_file, repos = NULL, type = "source")
# Attach
library(RfEmpImp)
```


## Prediction-based imputation
### For mixed types of variables
With version `2.0.0`, the names of parameters were further simplified, please
refer to the documentation for details.  
For data with mixed types of variables, `RfEmp` method is a short cut for
using `RfPred.Emp` for continuous variables and `RfPred.Cate` for categorical
variables (of type `logical` or `factor`, etc.).

### Prediction-based imputation for continuous variables
For continuous variables, in `RfPred.Emp` method, the empirical distribution of
random forest's out-of-bag prediction errors is used to construct the conditional
distributions of the variable under imputation, providing conditional
distributions with better quality. Users can set `method = "rfpred.emp"`
in function call to `mice` to use it.

Also, in `RfPred.Norm` method, normality was assumed for RF prediction errors,
as proposed by Shah *et al.*, and users can set `method = "rfpred.norm"`
in function call to `mice` to use it.

### Prediction-based imputation for categorical variables
For categorical variables, in `RfPred.Cate` method, the probability machine
theory is used, and the predictions of missing categories are based on the
predicted probabilities for each missing observation. Users can set 
`method = "rfpred.cate"` in function call to `mice` to use it.

### Example:
```r
# Prepare data
df <- nhanes
df[, c("age", "hyp")] <- lapply(X = nhanes[, c("age", "hyp")], FUN = as.factor)
# Do imputation
imp <- imp.rfemp(df)
# Do analyses
regObj <- with(imp, lm(chl ~ bmi + hyp))
# Pool analyzed results
poolObj <- pool(regObj)
# Extract estimates
res <- reg.ests(poolObj)
```

## Node-based imputation
For both continuous variables, the observations under the predicting nodes of
random forest are used as candidates for imputation.  
Two methods are now available for the `RfNode` algorithm.

### Node-based imputation using predicting nodes
`RfNode.Cond` uses the conditional distribution formed by the prediction nodes,
i.e. the weight changes of observations caused by the bootstrapping of random
forest are considered, and uses "in-bag" observations only. Users can set 
`method = "rfnode.cond"` in function call to `mice` to use it.

### Node-based imputation using proximities
`RfNode.Prox` uses the concepts of proximity matrices of random forests, and
observations fall under the same predicting nodes are used as candidates for
imputation.  Users can set `method = "rfnode.prox"` in function call to `mice`
to use it.

### Example:
```r
# Prepare data
df <- nhanes
df[, c("age", "hyp")] <- lapply(X = nhanes[, c("age", "hyp")], FUN = as.factor)
# Do imputation
imp <- imp.rfnode.cond(df)
# Or: imp <- imp.rfnode.prox(df)
# Do analyses
regObj <- with(imp, lm(chl ~ bmi + hyp))
# Pool analyzed results
poolObj <- pool(regObj)
# Extract estimates
res <- reg.ests(poolObj)
```


## Support for parallel computation
As random forest can be compute-intensive itself, and during multiple imputation
process, random forest models will be built for the variables containing missing
data for a certain number of iterations (usually 5 to 10 times) repeatedly
(usually 5 to 20 times), so computational efficiency is of crucial
importance for multiple imputation using chained random forests, especially for
large data sets.  
So in `RfEmpImp`, the random forest model building process is accelerated using
parallel computation powered by [`ranger`](https://CRAN.R-project.org/package=ranger).
The ranger R package provides support for parallel computation using native C++.
In our simulations, parallel computation can provide impressive performance boost
for imputation process (about 4x faster on a quad-core laptop).


## References
1. Hong, Shangzhi, et al. "Multiple imputation using chained random forests."
Preprint, submitted April 30, 2020. https://arxiv.org/abs/2004.14823.
2. Zhang, Haozhe, et al. "Random forest prediction intervals."
The American Statistician (2019): 1-15.
3. Wright, Marvin N., and Andreas Ziegler. "ranger: A Fast Implementation of
Random Forests for High Dimensional Data in C++ and R." Journal of Statistical
Software 77.i01 (2017).
4. Shah, Anoop D., et al. "Comparison of random forest and parametric imputation
models for imputing missing data using MICE: a CALIBER study." American journal
of epidemiology 179.6 (2014): 764-774.
5. Doove, Lisa L., Stef Van Buuren, and Elise Dusseldorp. "Recursive partitioning
for missing data imputation in the presence of interaction effects."
Computational Statistics & Data Analysis 72 (2014): 92-104.
6. Malley, James D., et al. "Probability machines." Methods of information in
medicine 51.01 (2012): 74-81.
